{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01bfa1a9-362c-478d-8025-06326c2ea9bf",
   "metadata": {},
   "source": [
    "# Predicting Electricity Infrastructure Induced Wildfire Risk in California\n",
    "\n",
    "\n",
    "Created by: Mengqi Yao [Last updated 06/27/22]\n",
    "\n",
    "This is the main notebook for the risk models built in the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ff6383-4335-4e2e-89cc-7df7fbaee91d",
   "metadata": {},
   "source": [
    "## PGE Data Sources\n",
    "\n",
    "The following data sources are used (also cited) in this work. These are primarily data provided by PG&E. \n",
    "\n",
    "| Name of Data | Link | Instructions |\n",
    "|:-:|:-:|:-:|\n",
    "|**Feeder data**| [ICA Map Geospatial data](https://www.pge.com/b2b/distribution-resource-planning/integration-capacity-map.shtml)|You may need to make a PGE account to access the map. Then in the top right hand corner, click on the 'Download Spatial Data' button. The ICADisplay.gdb geodatabase should be downloaded.| \n",
    "|**Infrastructure component characteristics**| [WMP Data](https://pspsinfo.ss.pge.com/rr/artifacts/wildfire-mitigation-data/Attachment-6-GIS-Files.zip)|Including transformer, support structure (pole), and overhead conductor features. Download the 'Attachment 6: GIS Files' .zip file. Unzip locally. There should be 2 folders inside the main Attachments folder. Unzip the 'EDGIS2-12.gdb' folder. You may need to unzip the subfolders inside the EDGIS2-12 folder.  |\n",
    "|**Fire incidents 2014-2019**| [WMP Data](https://www.pge.com/pge_global/common/pdfs/safety/emergency-preparedness/natural-disaster/wildfires/wildfire-mitigation-plan/SDR.zip)| Unzip, in the SDR Attachments, you will find IGNITIONS.gdb |\n",
    "|**Wire Down events 2015-2019**| [WMP Data](https://www.pge.com/pge_global/common/pdfs/safety/emergency-preparedness/natural-disaster/wildfires/wildfire-mitigation-plan/SDR.zip)| In the SDR Spreadsheet.xlsx|\n",
    "|**Additional conductor characteristics**| [WMP Data](https://www.pge.com/pge_global/common/pdfs/safety/emergency-preparedness/natural-disaster/wildfires/wildfire-mitigation-plan/reference-docs/MGRA007.zip)| More details on conductor|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d25b8-cfa9-4c51-950a-5511f7d80530",
   "metadata": {},
   "source": [
    "## Aggregated feeder and Transmission line data\n",
    "\n",
    "We merged the weather and vegetation data with the infrastructure data using feeder circuit IDs or transmission line names. Each record of the resulting combined dataset represents all features of one feeder or transmission line on a calendar day. We also recorded the total number of historical ignitions and wire-down events that happened on that circuit prior to that day.  We added binary fields indicating whether or not an ignition or wire-down happened on the day in question.  We relate ignition and wire-down events to the weather on the day when the event happened.\n",
    "\n",
    "Feeder: https://drive.google.com/file/d/14IdZV7llwn5qp3uf8vIXtMU_AOVjoPXu/view?usp=sharing\n",
    "\n",
    "Transmission line: https://drive.google.com/file/d/17XwtHXBp34hK2dvK2JMLPDY7fEJUQQk3/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ee262d-ff1c-4c81-8def-e08a5ed3597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import re\n",
    "import datetime\n",
    "from numpy import mean\n",
    "\n",
    "# plot library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import fiona\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import collections \n",
    "import math\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85257d0a-6a7f-420d-9b6c-4fca40f0c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML packages\n",
    "from datetime import timedelta\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import accuracy_score,balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import calibration_curve\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f779299-94a3-4968-9073-4919b9a0e068",
   "metadata": {},
   "source": [
    "# Feeder Risk Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ce54fd-1837-4a34-abdf-53497c8b6fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Year', 'Time Period', 'FeederID', 'VOLTNUM', 'Total Miles',\n",
       "       'Tier 2 Miles Proportion', 'Tier 3 Miles Proportion',\n",
       "       'Zone 1 Miles Proportion', 'HFTDMILES Proportion',\n",
       "       'Primary Conductor OH Proportion', 'Average Transformers Age',\n",
       "       'Transformer Climate Zone_R', 'Transformer Climate Zone_S',\n",
       "       'Transformer Climate Zone_T', 'Transformer Climate Zone_UNK',\n",
       "       'Transformer Climate Zone_X', 'Average Support Structure Age',\n",
       "       'Support Structure Material_ALM', 'Support Structure Material_CNCT',\n",
       "       'Support Structure Material_CNTR', 'Support Structure Material_FIBR',\n",
       "       'Support Structure Material_GUYP', 'Support Structure Material_LS',\n",
       "       'Support Structure Material_OTH', 'Support Structure Material_PUSH',\n",
       "       'Support Structure Material_S', 'Support Structure Material_STEL',\n",
       "       'Support Structure Material_THBR', 'Support Structure Material_TREE',\n",
       "       'Support Structure Material_UNK', 'Support Structure Material_WOOD',\n",
       "       'Support Structure Material_WOST', 'Average Primary OH Conductor Age',\n",
       "       'PriOH Conductor Construction Type_1.0',\n",
       "       'PriOH Conductor Construction Type_2.0',\n",
       "       'PriOH Conductor Construction Type_3.0',\n",
       "       'PriOH Conductor Construction Type_9.0',\n",
       "       'PrioH Conductor Wind Speed Code_2.0',\n",
       "       'PrioH Conductor Wind Speed Code_3.0',\n",
       "       'PrioH Conductor Wind Speed Code_4.0',\n",
       "       'OH Conductor Material Length Proportion_AAC',\n",
       "       'OH Conductor Material Proportion_ACSR',\n",
       "       'OH Conductor Material Length Proportion_Copper',\n",
       "       'OH Conductor Material Proportion_Other',\n",
       "       'OH Conductor Material Proportion_Null', 'Burning Index Max', 'ERC Max',\n",
       "       'ETR Min', 'FM1000 Min', 'FM100 Min', 'PET Min', 'PR Min', 'RMIN Min',\n",
       "       'SPH Min', 'SRAD Max', 'TMMX Max', 'VPD Max', 'GridMET WS Max',\n",
       "       'Distance from feeder to nearest Weather Station', 'max_wind_speed',\n",
       "       'mean_wind_speed', 'max_gust_speed', 'max_air_tempature',\n",
       "       'min_relative_humidify', 'CanopyHt_Mean', 'CanopyHt_Max',\n",
       "       'Historical Ignition Count', 'Hist WD Count', 'Wire Down', 'Ignitions',\n",
       "       'Filtered Wire Down', 'Ignitions Caused by Wire Downs',\n",
       "       'Vegetation Contact Ignitions', 'Equipment Failure Ignitions', 'Month',\n",
       "       'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_feather('feeder_daily.ftr')\n",
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b6603c-20e6-44c3-9059-632d9401bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "    plt.xlim([-0.5,100])\n",
    "    plt.ylim([0,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    return fp, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b419ab-0d91-4916-b864-534ea9e7918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my own recall function\n",
    "\n",
    "def p_recall_scroe(y_true, y_pred):\n",
    "    score = recall_score(y_true, y_pred, average=None)\n",
    "    final_score = score[1]\n",
    "    return final_score\n",
    "\n",
    "def n_recall_scroe(y_true, y_pred):\n",
    "    score = recall_score(y_true, y_pred, average=None)\n",
    "    final_score = score[0]\n",
    "    return final_score\n",
    "\n",
    "# cross validation\n",
    "def CV_score(kfold, X, y, model):\n",
    "    p_recall = []\n",
    "    n_recall = []\n",
    "    auc_score = []\n",
    "    for train_ix, test_ix in tqdm(kfold.split(X, y)):\n",
    "        # select rows\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        \n",
    "       \n",
    "        clf = model.fit(train_X, train_y)\n",
    "        y_hat = clf.predict(test_X)\n",
    "        y_prob = clf.predict_proba(test_X)[:,1]\n",
    "        #train_0, train_1 = len(train_y[train_y==0]), len(train_y[train_y==1])\n",
    "        #test_0, test_1 = len(test_y[test_y==0]), len(test_y[test_y==1])\n",
    "        #print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))    \n",
    "\n",
    "        p_recall.append(p_recall_scroe(test_y, y_hat))\n",
    "        n_recall.append(n_recall_scroe(test_y, y_hat))\n",
    "        auc_score.append(roc_auc_score(test_y, y_prob))\n",
    "\n",
    "\n",
    "    print('>--------final p recall-----------<')\n",
    "    print('>Mean: %f' % (mean(p_recall)))\n",
    "    print('>STD: %f' % (np.std(p_recall)))\n",
    "    print('>--------final n recall-----------<')\n",
    "    print('>Mean: %f' % (mean(n_recall)))\n",
    "    print('>STD: %f' % (np.std(n_recall)))\n",
    "    print('>--------final ROC-----------<')\n",
    "    print('>Mean: %f' % (mean(auc_score)))\n",
    "    print('>STD: %f' % (np.std(auc_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13de87-ce48-4b23-8f7b-4b4164991687",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c035e7ce-1033-44ee-bc34-7ae2f5909e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VOLTNUM', 'Total Miles', 'Tier 2 Miles Proportion',\n",
       "       'Tier 3 Miles Proportion', 'Zone 1 Miles Proportion',\n",
       "       'HFTDMILES Proportion', 'Primary Conductor OH Proportion',\n",
       "       'Average Transformers Age', 'Transformer Climate Zone_R',\n",
       "       'Transformer Climate Zone_S', 'Transformer Climate Zone_T',\n",
       "       'Transformer Climate Zone_UNK', 'Transformer Climate Zone_X',\n",
       "       'Average Support Structure Age', 'Support Structure Material_ALM',\n",
       "       'Support Structure Material_CNCT', 'Support Structure Material_CNTR',\n",
       "       'Support Structure Material_FIBR', 'Support Structure Material_GUYP',\n",
       "       'Support Structure Material_LS', 'Support Structure Material_OTH',\n",
       "       'Support Structure Material_PUSH', 'Support Structure Material_S',\n",
       "       'Support Structure Material_STEL', 'Support Structure Material_THBR',\n",
       "       'Support Structure Material_TREE', 'Support Structure Material_UNK',\n",
       "       'Support Structure Material_WOOD', 'Support Structure Material_WOST',\n",
       "       'Average Primary OH Conductor Age',\n",
       "       'PriOH Conductor Construction Type_1.0',\n",
       "       'PriOH Conductor Construction Type_2.0',\n",
       "       'PriOH Conductor Construction Type_3.0',\n",
       "       'PriOH Conductor Construction Type_9.0',\n",
       "       'PrioH Conductor Wind Speed Code_2.0',\n",
       "       'PrioH Conductor Wind Speed Code_3.0',\n",
       "       'PrioH Conductor Wind Speed Code_4.0',\n",
       "       'OH Conductor Material Length Proportion_AAC',\n",
       "       'OH Conductor Material Proportion_ACSR',\n",
       "       'OH Conductor Material Length Proportion_Copper',\n",
       "       'OH Conductor Material Proportion_Other',\n",
       "       'OH Conductor Material Proportion_Null', 'Burning Index Max', 'ERC Max',\n",
       "       'ETR Min', 'FM1000 Min', 'FM100 Min', 'PET Min', 'PR Min', 'RMIN Min',\n",
       "       'SPH Min', 'SRAD Max', 'TMMX Max', 'VPD Max', 'GridMET WS Max',\n",
       "       'Distance from feeder to nearest Weather Station', 'max_wind_speed',\n",
       "       'mean_wind_speed', 'max_gust_speed', 'max_air_tempature',\n",
       "       'min_relative_humidify', 'CanopyHt_Mean', 'CanopyHt_Max',\n",
       "       'Historical Ignition Count', 'Hist WD Count', 'Ignitions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_raw.copy()\n",
    "\n",
    "# we take wildfire season in 2019 as the test data\n",
    "mask_test = (df['Year']  == 2019) & (df['Week']  > 21) & (df['Week']  < 49)\n",
    "test_df = df[mask_test]\n",
    "\n",
    "# split by year\n",
    "mask = (df['Year'] <2019) \n",
    "\n",
    "train_df = df[mask]\n",
    "test_save = test_df[['FeederID','Year','Day','Ignitions']]\n",
    "\n",
    "train_df = train_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "test_df = test_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16f6ecb-aba8-49aa-91b3-4ed37d27f97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (1981502,)\n",
      "Test labels shape: (283811,)\n",
      "Training features shape: (1981502, 65)\n",
      "Test features shape: (283811, 65)\n"
     ]
    }
   ],
   "source": [
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Ignitions'))\n",
    "bool_train_labels = train_labels != 0\n",
    "test_labels = np.array(test_df.pop('Ignitions'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "# standarlize data\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled = scaler.fit_transform(train_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "train_features_scaled = np.clip(train_features_scaled, -5, 5)\n",
    "test_features_scaled = np.clip(test_features_scaled, -5, 5)\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features_scaled.shape)\n",
    "print('Test features shape:', test_features_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5cf0fd-ccf2-43af-8ceb-daba9484d29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66755051571957\n"
     ]
    }
   ],
   "source": [
    "#Plain LR model\n",
    "lgm = linear_model.LogisticRegression(fit_intercept=True, solver = 'liblinear', max_iter=10000,random_state = 42,C=0.0001)\n",
    "lgm.fit(train_features_scaled, train_labels)\n",
    "test_prob = lgm.predict_proba(test_features_scaled)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f192a607-fd53-47f5-a5d6-722cd454cc8d",
   "metadata": {},
   "source": [
    "### Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f761178b-65d7-4fb3-b353-87dac8e98ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343651152382984\n"
     ]
    }
   ],
   "source": [
    "lgm_us = linear_model.LogisticRegression(fit_intercept=True, solver = 'liblinear', max_iter=10000,random_state = 42,C=0.0001)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_resample, y_resample = undersample.fit_resample(train_features_scaled, train_labels)\n",
    "lgm_us.fit(X_resample, y_resample)\n",
    "\n",
    "\n",
    "test_prob = lgm_us.predict_proba(test_features_scaled)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e5f35-e645-42b2-b325-71695e1355df",
   "metadata": {},
   "source": [
    "### Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ca899f-b949-4d56-80a0-801d2e3b4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7559070932311038\n"
     ]
    }
   ],
   "source": [
    "lgm_os = linear_model.LogisticRegression(fit_intercept=True, solver = 'liblinear', max_iter=10000,random_state = 42,C=0.0001)\n",
    "\n",
    "\n",
    "bool_train_labels = train_labels != 0\n",
    "\n",
    "pos_features = train_features_scaled[bool_train_labels]\n",
    "neg_features = train_features_scaled[~bool_train_labels]\n",
    "\n",
    "pos_labels = train_labels[bool_train_labels]\n",
    "neg_labels = train_labels[~bool_train_labels]\n",
    "\n",
    "ids = np.arange(len(pos_features))\n",
    "choices = np.random.choice(ids, len(neg_features))\n",
    "\n",
    "\n",
    "res_pos_features = pos_features[choices]\n",
    "res_pos_labels = pos_labels[choices]\n",
    "\n",
    "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
    "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
    "\n",
    "order = np.arange(len(resampled_labels))\n",
    "np.random.shuffle(order)\n",
    "X_resample = resampled_features[order]\n",
    "y_resample = resampled_labels[order]\n",
    "\n",
    "lgm_os.fit(X_resample, y_resample)\n",
    "\n",
    "test_prob = lgm_os.predict_proba(test_features_scaled)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6693e0dc-ee73-4a61-aca0-eff59aef80ab",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1723bfc6-ce24-4eb1-b2ab-3668e1ee9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7555044811043905\n"
     ]
    }
   ],
   "source": [
    "lgm_SMOTE = linear_model.LogisticRegression(fit_intercept=True, solver = 'liblinear', max_iter=10000,random_state = 42,C=0.0001)\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_resample, y_resample = pipeline.fit_resample(train_features_scaled, train_labels)\n",
    "\n",
    "lgm_SMOTE.fit(X_resample,y_resample)\n",
    "\n",
    "test_prob = lgm_SMOTE.predict_proba(test_features_scaled)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98b299-d91f-47b5-8dbc-b0263077cc86",
   "metadata": {},
   "source": [
    "### Blanced Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8431a1a-6ef9-474a-b30a-79eab4c00f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756676501038205\n"
     ]
    }
   ],
   "source": [
    "lgm_bw = linear_model.LogisticRegression(fit_intercept=True, solver = 'liblinear', max_iter=10000,class_weight='balanced',random_state = 42,C=0.0001)\n",
    "lgm_bw.fit(train_features_scaled, train_labels)\n",
    "test_prob = lgm_bw.predict_proba(test_features_scaled)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1455d68-3875-405d-957c-e3dd9eaf5cd8",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0040ee4e-700a-4d34-8579-8b21be6f80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (1981502,)\n",
      "Test labels shape: (283811,)\n",
      "Training features shape: (1981502, 65)\n",
      "Test features shape: (283811, 65)\n"
     ]
    }
   ],
   "source": [
    "df = data_raw.copy()\n",
    "\n",
    "mask_test = (df['Year']  == 2019) & (df['Week']  > 21) & (df['Week']  < 49)\n",
    "test_df = df[mask_test]\n",
    "\n",
    "# split by year\n",
    "mask = (df['Year'] <2019) \n",
    "\n",
    "train_df = df[mask]\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "test_df = test_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "train_df.columns\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Ignitions'))\n",
    "bool_train_labels = train_labels != 0\n",
    "test_labels = np.array(test_df.pop('Ignitions'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "885dfd6f-9ff7-4549-97c4-19416a3386d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565781051629482\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators =100, \n",
    "                               max_features = 'sqrt',\n",
    "                               min_samples_split= 3500,\n",
    "                               min_samples_leaf = 10, \n",
    "                               bootstrap = 'True', \n",
    "                               random_state = 42)\n",
    "rf.fit(train_features, train_labels)\n",
    "test_prob = rf.predict_proba(test_features)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b18ec6-7e48-4001-9fbd-d89f5d6008b6",
   "metadata": {},
   "source": [
    "### Balanced Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44342fcc-b6dc-4407-a0ec-ee28faf85e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761450110546642\n"
     ]
    }
   ],
   "source": [
    "rf_BW = RandomForestClassifier(n_estimators =100, \n",
    "                               max_features = 'sqrt',\n",
    "                               min_samples_split= 3500,\n",
    "                               min_samples_leaf = 10, \n",
    "                               bootstrap = 'True', \n",
    "                               random_state = 42,\n",
    "                               class_weight='balanced')\n",
    "\n",
    "rf_BW.fit(train_features, train_labels)\n",
    "test_prob = rf_BW.predict_proba(test_features)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46afbdaf-3a23-418d-8b3a-8a4ef78c66ec",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c056e7c-7c6f-4bcd-be3a-8a71231040a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7354004638850751\n"
     ]
    }
   ],
   "source": [
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "X_resample, y_resample = pipeline.fit_resample(train_features, train_labels)\n",
    "\n",
    "rf.fit(X_resample,y_resample)\n",
    "\n",
    "test_prob = rf.predict_proba(test_features)[:,1]\n",
    "print(roc_auc_score(test_labels, test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb35181-20a0-41a9-a3ca-9a084c6f12c4",
   "metadata": {},
   "source": [
    "## HGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b1ed8ce-7543-4ad7-865d-d1989e22b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (1981502,)\n",
      "Test labels shape: (283811,)\n",
      "Training features shape: (1981502, 65)\n",
      "Test features shape: (283811, 65)\n"
     ]
    }
   ],
   "source": [
    "df = data_raw.copy()\n",
    "\n",
    "mask_test = (df['Year']  == 2019) & (df['Week']  > 21) & (df['Week']  < 49)\n",
    "test_df = df[mask_test]\n",
    "\n",
    "# split by year\n",
    "mask = (df['Year'] <2019) \n",
    "\n",
    "train_df = df[mask]\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "test_df = test_df.drop(columns =['Year','Day','Month', 'Week','Time Period','FeederID','Wire Down','Filtered Wire Down','Ignitions Caused by Wire Downs','Vegetation Contact Ignitions','Equipment Failure Ignitions']) \n",
    "train_df.columns\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Ignitions'))\n",
    "bool_train_labels = train_labels != 0\n",
    "test_labels = np.array(test_df.pop('Ignitions'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b2c5cd7-fb83-443f-a83b-af5781f19b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=40, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=40\n",
      "0.7755520538893953\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         learning_rate = 0.3,\n",
    "                         max_bin=63,\n",
    "                         n_estimators=150,\n",
    "                         min_data_in_leaf = 40,\n",
    "                         max_depth = 2)\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator = clf,\n",
    "                                sampling_strategy = 'majority',\n",
    "                                random_state=42)\n",
    "bbc.fit(train_features,train_labels)\n",
    "test_prob = bbc.predict_proba(test_features)[:,1]\n",
    "print(roc_auc_score( test_labels,test_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc286bc-0406-4863-a53d-0969b084423c",
   "metadata": {},
   "source": [
    "# Transmission Line Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0d8863-87c8-4e34-9b16-0fd27e1efb10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Year', 'Day', 'max_wind_speed', 'max_gust_speed',\n",
       "       'max_air_tempature', 'min_relative_humidify', 'mean_wind_speed: mean',\n",
       "       'Date', 'Stations', 'T-Line Name', 'kV', 'Length', 'Wire Down',\n",
       "       'Cause Category', 'Cause Details', 'BI Max', 'ERC Max', 'ETR Min',\n",
       "       'FM1000 Min', 'FM100 Min', 'PET Min', 'PR Min', 'RH Min', 'SPH Min',\n",
       "       'SRAD Max', 'TMAX Max', 'VPD Max', 'WS Max', 'CanopyHt_Mean',\n",
       "       'CanopyHt_Max', 'min_dis', 'mean_dis', 'Hist WD Count', 'Week'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = pd.read_feather('TL_daily.ftr')\n",
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9631b5f5-8041-45b1-950d-786f0f53f192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['max_wind_speed', 'max_gust_speed', 'max_air_tempature',\n",
      "       'min_relative_humidify', 'mean_wind_speed: mean', 'kV', 'Length',\n",
      "       'Wire Down', 'BI Max', 'ERC Max', 'ETR Min', 'FM1000 Min', 'FM100 Min',\n",
      "       'PET Min', 'PR Min', 'RH Min', 'SPH Min', 'SRAD Max', 'TMAX Max',\n",
      "       'VPD Max', 'WS Max', 'CanopyHt_Mean', 'CanopyHt_Max', 'min_dis',\n",
      "       'mean_dis', 'Hist WD Count'],\n",
      "      dtype='object')\n",
      "Training labels shape: (91097,)\n",
      "Test labels shape: (23237,)\n",
      "Training features shape: (91097, 25)\n",
      "Test features shape: (23237, 25)\n"
     ]
    }
   ],
   "source": [
    "df = data_raw.copy()\n",
    "\n",
    "mask_test = (df['Year']  == 2019) \n",
    "test_df = df[mask_test]\n",
    "\n",
    "# split by year\n",
    "mask = (df['Year'] <2019) \n",
    "\n",
    "train_df = df[mask]\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns =['Year','Day', 'Week','index','Date', 'Stations', 'T-Line Name','Cause Category', 'Cause Details']) \n",
    "test_df = test_df.drop(columns =['Year','Day', 'Week','index','Date', 'Stations', 'T-Line Name','Cause Category', 'Cause Details']) \n",
    "print(train_df.columns)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Wire Down'))\n",
    "bool_train_labels = train_labels != 0\n",
    "test_labels = np.array(test_df.pop('Wire Down'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "test_features = np.array(test_df)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecb4c9b-109b-4b80-9a47-bb635caaa325",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.LGBMClassifier(boosting_type='gbdt',\n",
    "                         importance_type='gain',\n",
    "                         learning_rate = 0.1,\n",
    "                         max_bin=15,\n",
    "                         n_estimators=10,\n",
    "                         min_data_in_leaf = 40,\n",
    "                         max_depth = 2)\n",
    "\n",
    "bbc = BalancedBaggingClassifier(base_estimator = clf,\n",
    "                                sampling_strategy = 'majority',\n",
    "                                random_state=42)\n",
    "\n",
    "bbc.fit(train_features,train_labels)\n",
    "\n",
    "roc_auc_score(test_labels, bbc.predict_proba(test_features)[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "437032c7-957f-49b4-88a9-2ac4fe84403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866259645643833"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_BW = RandomForestClassifier(n_estimators =100, \n",
    "                               max_features = 'sqrt',\n",
    "                               min_samples_split= 10,\n",
    "                               min_samples_leaf = 14, \n",
    "                               bootstrap = 'True', \n",
    "                               random_state = 42,\n",
    "                               class_weight='balanced')\n",
    "rf_BW.fit(train_features,train_labels)\n",
    "\n",
    "roc_auc_score(test_labels, rf_BW.predict_proba(test_features)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4d2d3-ce08-417d-9e8d-17d2a6a8b606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
